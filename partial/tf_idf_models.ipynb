{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-idf models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install contractions\n",
        "!pip install nltk\n",
        "!pip install numpy\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import unidecode\n",
        "import contractions\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaijTGt6batz",
        "outputId": "65efaa41-b65c-4c18-bedc-4b9c8424c155"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.72)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextNormalizer:\n",
        "    def normalize(self, text, verbose=False):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class SimpleTextNormalizer:\n",
        "    def __init__(self):\n",
        "        self.punctuation_table = str.maketrans('','', string.punctuation)\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    \n",
        "    def normalize(self, text, verbose=False):\n",
        "        # remove extra withespaces\n",
        "        text = re.sub(' +', ' ', text)\n",
        "\n",
        "        # convert unicode characters to ascii\n",
        "        text = unidecode.unidecode(text)\n",
        "\n",
        "        # convert text to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # expand the contractions so this words can be removed\n",
        "        text = contractions.fix(text)\n",
        "\n",
        "        # remove punctuation symbols\n",
        "        text = text.translate(self.punctuation_table)\n",
        "\n",
        "        # tokenize the text\n",
        "        words = word_tokenize(text)\n",
        "\n",
        "        result = []\n",
        "        for w in words:\n",
        "            w = w.strip() # remove possible trailing spaces \n",
        "            if w in self.stop_words: # discard stopword\n",
        "                continue\n",
        "            w = self.lemmatizer.lemmatize(w) # lemmatize the word\n",
        "            if w not in self.stop_words: # discard stopword\n",
        "                result.append(w)\n",
        "\n",
        "        return result       "
      ],
      "metadata": {
        "id": "2X3XFFqYblXX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "class FrequencyModel:\n",
        "    def __init__(self, text_normalizer):\n",
        "        self.text_normalizer = text_normalizer\n",
        "        self.tf_table = {}\n",
        "        self.idf_table = {}\n",
        "        self.doc_len = {}\n",
        "        self.doc_max_tf = {}\n",
        "        self.corpus_len = 0\n",
        "        self.avg_doc_len = 0\n",
        "\n",
        "    def fit(self, corpus, normalized_tf=True):\n",
        "        for doc in corpus:\n",
        "            self.corpus_len += 1\n",
        "            self.doc_max_tf[doc.doc_id] = 0\n",
        "\n",
        "            terms = self.text_normalizer.normalize(doc.text)\n",
        "            doc_tf = Counter(terms)\n",
        "            self.doc_len[doc.doc_id] = len(doc_tf)\n",
        "            self.avg_doc_len += len(doc_tf)\n",
        "\n",
        "            for term, freq in doc_tf.items():\n",
        "                try:\n",
        "                    self.tf_table[term][doc.doc_id] = freq\n",
        "                except KeyError:\n",
        "                    self.tf_table[term] = {doc.doc_id : freq}\n",
        "                \n",
        "                self.doc_max_tf[doc.doc_id] = max(self.doc_max_tf[doc.doc_id], freq)\n",
        "\n",
        "        self.avg_doc_len /= self.corpus_len\n",
        "            \n",
        "        for term in self.tf_table:\n",
        "            self.idf_table[term] = self._compute_idf(term)\n",
        "\n",
        "            if normalized_tf:\n",
        "                for doc, freq in self.tf_table[term].items():\n",
        "                    self.tf_table[term][doc] = freq / self.doc_max_tf[doc]\n",
        "\n",
        "    def _compute_idf(self, term):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    \n",
        "    def retrieve(self, query):\n",
        "        raise NotImplementedError()  "
      ],
      "metadata": {
        "id": "LWQZmfYnqRsW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorSpaceModel(FrequencyModel):\n",
        "    def fit(self, corpus):\n",
        "        super().fit(corpus)\n",
        "\n",
        "        self.doc_norm = {}\n",
        "        for term, docs in self.tf_table.items():\n",
        "            for doc, freq in docs.items():\n",
        "                self.doc_norm[doc] = self.doc_norm.get(doc, 0) + (self.tf_table[term][doc] * self.idf_table[term]) ** 2\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        a = 0.4\n",
        "        terms = self.text_normalizer.normalize(query)\n",
        "        counter = Counter(terms)\n",
        "        max_freq = max(counter.values())\n",
        "\n",
        "        score = {}\n",
        "        query_norm = 0\n",
        "        for term, freq in counter.items():\n",
        "            if term not in self.tf_table:\n",
        "                continue\n",
        "            # compute weight of the term in the query\n",
        "            w_iq = self.idf_table[term] *(a + (1-a) * freq / max_freq) \n",
        "            query_norm += w_iq ** 2\n",
        "\n",
        "            # only check documents where appears the term\n",
        "            for doc, tf in self.tf_table[term].items():\n",
        "                try:\n",
        "                    score[doc] += w_iq * tf * self.idf_table[term]\n",
        "                except:\n",
        "                    score[doc] = w_iq * tf * self.idf_table[term]\n",
        "        \n",
        "        for doc in score:\n",
        "            score[doc] = score[doc] / np.sqrt(w_iq * self.doc_norm[doc]) \n",
        "        return sorted(score.items(), key=lambda item: item[1], reverse=True)\n",
        "         \n",
        "    def _compute_idf(self, term):\n",
        "        return np.log10(self.corpus_len / len(self.tf_table[term]))\n",
        "  "
      ],
      "metadata": {
        "id": "ao7UnbVG9x_G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OkapiBM25Model(FrequencyModel):\n",
        "    def __init__(self, text_normalizer, k1=1.5, b=0.75):\n",
        "        super().__init__(text_normalizer)\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        terms = self.text_normalizer.normalize(query)\n",
        "        counter = Counter(terms)\n",
        "        max_freq = max(counter.values())\n",
        "\n",
        "        score = {}\n",
        "        for term, freq in counter.items():\n",
        "            if term not in self.tf_table:\n",
        "                continue\n",
        "            for doc, tf in self.tf_table[term].items():\n",
        "                numerator = self.idf_table[term] * self.tf_table[term][doc] * (self.k1 + 1)\n",
        "                denominator = self.tf_table[term][doc] + self.k1 * (1 - self.b + self.b * self.doc_len[doc] / self.avg_doc_len)\n",
        "                try:\n",
        "                    score[doc] += numerator/denominator\n",
        "                except:\n",
        "                    score[doc] = numerator/denominator\n",
        "        \n",
        "        return sorted(score.items(), key=lambda item: item[1], reverse=True)\n",
        "         \n",
        "    def _compute_idf(self, term):\n",
        "        return np.log10( 1 + (self.corpus_len - len(self.tf_table[term]) + 0.5) / len(self.tf_table[term]) + 0.5)\n",
        "  "
      ],
      "metadata": {
        "id": "0jrupsOdcw35"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ir_datasets\n",
        "!pip install pandas\n",
        "import ir_datasets\n",
        "import pandas as pd\n",
        "cranfield = ir_datasets.load('cranfield')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UayOh8z-_PTc",
        "outputId": "628b384a-6e69-4fc9-f448-ca25f3c7b367"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ir_datasets in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: lz4>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (4.0.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (4.64.0)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (0.2.3)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (2.6)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (0.2.5)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (4.8.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (4.6.3)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (3.1.4)\n",
            "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (0.1.8)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (2.23.0)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (0.1.5)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets) (6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->ir_datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->ir_datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->ir_datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->ir_datasets) (1.24.3)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cranfield.qrels_defs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHhujx0HVQXJ",
        "outputId": "c2e4f8f5-3f23-4333-a73e-feaf42bee53e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{-1: 'References of no interest.',\n",
              " 1: 'References of minimum interest, for example, those that have been included from an historical viewpoint.',\n",
              " 2: 'References which were useful, either as general background to the work or as suggesting methods of tackling certain aspects of the work.',\n",
              " 3: 'References of a high degree of relevance, the lack of which either would have made the research impracticable or would have resulted in a considerable amount of extra work.',\n",
              " 4: 'References which are a complete answer to the question.'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some documents relevant to query 1 used for evaluation\n",
        "df = pd.DataFrame(filter(lambda x: x.query_id == \"1\", cranfield.qrels_iter()))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "6WCk5Ocyg8CB",
        "outputId": "cbd9faff-7b29-4d01-fba1-c02642f14fcd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   query_id doc_id  relevance iteration\n",
              "0         1    184          2         0\n",
              "1         1     29          2         0\n",
              "2         1     31          2         0\n",
              "3         1     12          3         0\n",
              "4         1     51          3         0\n",
              "5         1    102          3         0\n",
              "6         1     13          4         0\n",
              "7         1     14          4         0\n",
              "8         1     15          4         0\n",
              "9         1     57          2         0\n",
              "10        1    378          2         0\n",
              "11        1    859          2         0\n",
              "12        1    185          3         0\n",
              "13        1     30          3         0\n",
              "14        1     37          3         0\n",
              "15        1     52          4         0\n",
              "16        1    142          4         0\n",
              "17        1    195          4         0\n",
              "18        1    875          2         0\n",
              "19        1     56          3         0\n",
              "20        1     66          3         0\n",
              "21        1     95          3         0\n",
              "22        1    462          4         0\n",
              "23        1    497          3         0\n",
              "24        1    858          3         0\n",
              "25        1    876          3         0\n",
              "26        1    879          3         0\n",
              "27        1    880          3         0\n",
              "28        1    486         -1         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f91780b4-35f2-4936-b14f-a6f7a69eaf46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>relevance</th>\n",
              "      <th>iteration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>184</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>378</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>859</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>185</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>142</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>195</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>875</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>462</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>497</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>858</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>876</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>879</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>880</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>486</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f91780b4-35f2-4936-b14f-a6f7a69eaf46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f91780b4-35f2-4936-b14f-a6f7a69eaf46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f91780b4-35f2-4936-b14f-a6f7a69eaf46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_normalizer = SimpleTextNormalizer()\n",
        "vector_model = VectorSpaceModel(text_normalizer)\n",
        "vector_model.fit(cranfield.docs_iter())"
      ],
      "metadata": {
        "id": "rAExAM5bV-yZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = list(cranfield.queries_iter())[0]\n",
        "print(query)\n",
        "list(vector_model.retrieve(query.text))[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhcCtAYJWW9x",
        "outputId": "c48fd95f-c903-468e-e4ba-b176fe8243cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenericQuery(query_id='1', text='what similarity laws must be obeyed when constructing aeroelastic models\\nof heated high speed aircraft .')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('13', 1.0319418735338295),\n",
              " ('359', 1.0156193565682672),\n",
              " ('56', 0.8098472770603728),\n",
              " ('51', 0.7915209937794212),\n",
              " ('1186', 0.7204737576574822),\n",
              " ('665', 0.6829625562413993),\n",
              " ('12', 0.6549532419624435),\n",
              " ('1268', 0.5654093726232157),\n",
              " ('327', 0.557975578510696),\n",
              " ('486', 0.5561497215854606),\n",
              " ('746', 0.5273731520717708)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okapi_model = OkapiBM25Model(text_normalizer)\n",
        "okapi_model.fit(cranfield.docs_iter())"
      ],
      "metadata": {
        "id": "Vt01vnfyfQGM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = list(cranfield.queries_iter())[0]\n",
        "print(query)\n",
        "list(okapi_model.retrieve(query.text))[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GK1FKbVfY8j",
        "outputId": "4f711710-d41f-4afa-ba69-b44ea80072a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenericQuery(query_id='1', text='what similarity laws must be obeyed when constructing aeroelastic models\\nof heated high speed aircraft .')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('359', 3.44470422594676),\n",
              " ('12', 3.399315017424871),\n",
              " ('13', 3.370183889780178),\n",
              " ('184', 2.928419229117983),\n",
              " ('875', 2.758998415206621),\n",
              " ('429', 2.42491993791195),\n",
              " ('663', 2.410842356650673),\n",
              " ('51', 2.3318772977784348),\n",
              " ('1186', 2.3301020192507096),\n",
              " ('56', 2.305697295289492),\n",
              " ('141', 2.3042831156270567)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"enter your query here\""
      ],
      "metadata": {
        "id": "Lo2voAOthko0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okapi_model.retrieve(query)"
      ],
      "metadata": {
        "id": "TaWZLvVxho1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_model.retrieve(query)"
      ],
      "metadata": {
        "id": "3-q_LSluhttC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}